= Running Rust on an FPGA
:last-update-label!:
:imagesdir: images
:source-highlighter: rouge
:rouge-style: github
// :source-highlighter: highlight.js
// :highlightjs-languages: rust, cpp, console

== Introduction: Begin by introducing the topic of High-level synthesis (HLS) and its importance in the field of FPGA programming. Explain why you've chosen to focus on Rust as the programming language for HLS.

== What is High-level synthesis (HLS): Describe what HLS is, how it differs from traditional FPGA programming, and the benefits of using HLS.

Usually one would write code for an FPGA in a hardware description language (HDL) such as Verilog or VHDL. However, this is a very low-level language, and it is difficult to write code in it. This is where HLS comes in.

HLS is a process that allows developers to write high-level code, such as C/C++ or Rust code, and then use a toolchain to automatically convert that code into RTL (register-transfer level) code, which can be used to program an FPGA. This is different from traditional FPGA programming, where developers write RTL code directly.


== Why Rust for HLS: Explain why Rust is a good choice for HLS and how its features such as memory safety and thread safety align with the requirements of HLS.

== Building the toolchain: Describe the process of building the toolchain for HLS from Rust. Explain the different components of the toolchain, such as the Rust-to-C\++ translator and the C\++-to-RTL synthesis tool.

== First prototype: Describe the first prototype of your toolchain and the results you achieved. Show some examples of code written in Rust and the corresponding RTL generated by your toolchain.

== Future work: Discuss future work for your toolchain. This can include additional features or improvements that you plan to make.

== Conclusion: Summarize the key points of the blog post and explain why HLS is an important technology for FPGA programming.


== References: Include any references you used while writing the blog post.


== Writing Code that synthesizes well

Bambu is build to synthesize C/C++ code.

The example for a function that finds that minimum or maximum in an array is a good example of how to write code that synthesizes well. It is just very C-like code, that mutates its inputs and has a interface that is not very Rust-like.

[source,cpp]
----
include::src/min_max_cpp.cpp[]
----

The function takes a pointer to an array of integers, the number of elements in the array, and two pointers to integers. The function will find the minimum and maximum in the array and write them to the memory locations pointed to by `out_max` and `out_min`.

We synthesize the function using bambu and use bambus integrated test runner to test the function against some testcases. Later we will use the same testcases for the Rust version of the function. The optimization level is set to `-O2` for now.

.Testcases:
* input=[0,1,2,3,4] num_elements=5 out_max=0 out_min=4
* input=[15,10,5] num_elements=3 out_max=15 out_min=5 



.Synthesizing and testing the C++ function
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_clang_intro.log[]
----
====


The most relevant aspects of the output are the average number of clock cycles and the total area used. The area is an important metric, because it is the most expensive resource on FPGAs. The number of clock cycles is also important, because it is a reasonable indicator of how fast the function is. 

The tests are executed using verilator, so they are not completly representative of the actual hardware, because Verilator does not simulate timings beyond the clock cycles. So it could be that a design requires fewer cycles, but can only be run at a lower clock frequency. That said, comparing clock cycles should be a somewhat accurate.

Translating this to Rust is not very difficult. We need to access the input array in rust using `array.get_unchecked(i)` instead of `array[i]`, because the latter is always bounds checked. If we used the checked version, our code could panic, which is not synthesizable. Finally, we need to mark the function as `#[no_mangle]`, so that the function name is preserved.

[source,rust]
----
include::src/min_max_rust.rs[]
----

If we compile that code to LLVM IR and try to use bambu with it we get an error that `llvm.vector.reduce.smax.v4i32` is not supported. Bambu does not support llvm vector instructions. They probably get inserted by the https://llvm.org/docs/Vectorizers.html#the-loop-vectorizer[LLVM Loop Vectorizer]. We can disable that vectorization pass by passing `-C no-vectorize-loops` to rustc.


By default the Rust compiler generates code that unwinds the stack on panic. The generated LLVM IR also has a exception handling personality function added to every function in LLVM IR. Both are not synthesizable. We tell the compiler to instead termintate the program on panic by passing `-C panic=abort` to rustc. Terminating the program is also not synthesizable, but as long as we dont panic, it is fine.

We also need to disable overflow checks, because they will generate panics. We can do that by passing `-C overflow-checks=off` to rustc.

Finally, we need to pass `-C target-cpu=generic --target=unknown-unknown-unknown` to rustc, because we dont target the host CPU.

It is probably good idea to tell the rust compiler that we are not targeting a specific cpu architecture by passing `-C target-cpu=generic`.

The final command to compile the rust code to LLVM IR is:

[source,bash]
----
rustc --emit=llvm-ir --crate-type=lib src/min_max_rust.rs -o min_max_rust.ll -C opt-level=0 -C overflow-checks=off -C no-vectorize-loops -C target-cpu=generic -C panic=abort
----

Bambu fails to synthesize the rust code if optimizations are disabled. Enabling at least some level of optimization in rustc or enableing a level higher than 1 in bambu fixes the problem. We will set the optimization level to `-O2` in bambu, because that should have a smaller impact on the results than enabling optimizations in rustc.

.Output of synthesizing the rust function
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_intro.log[]
----
====

While taking up roughly the same amount of resources, the rust version need roughly 2 times less cycles to execute. For now I dont know why that is the case. I would have assumed that the rust version would be slower, because the cpp version had optimizations enabled during compilation and synthesis, while the rust version did not.

Lets try the cpp and the rust version with optimizations set to the maximum level.


.CPP with clang and `-O5`
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_clang_speed.log[]
----
====

.CPP with clang and `-Os`
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_clang_size.log[]
----
====

.CPP with gcc and `-O5`
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_gcc_speed.log[]
----
====

.CPP with gcc and `-Os`
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_gcc_size.log[]
----
====

.Rust with `-O5` and `-C opt-level=3`
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_speed.log[]
----

When using rust optimization levels _3_ or _2_ the bambu opt level does not matter for this example.
====

.Rust with `-Os` and `-C opt-level=s`
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_size.log[]
----

When using rust optimization levels _s_ the bambu opt level does not matter for this example.
====

A more idiomatic Rust version of the same function using slices and iterators.

[source,rust]
----
include::src/min_max_rust_idiomatic.rs[]
----

.Idiomatic rust with `-Os` and `-C opt-level=s`
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_idiomatic_size.log[]
----
====


.Idiomatic rust with `-O5` and `-C opt-level=3`
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_idiomatic_speed.log[]
----
====

While the idiomatic version is not faster than the non-idiomatic version, it takes up the smallest area of all synthesized design. It is also more readable and easier to understand.

[vegalite]
....
{
  "data": {
        "values": [
          {"id": "min_max_cpp_clang_size", "Setup": "C++ clang -Os"},
          {"id": "min_max_cpp_clang_speed", "Setup": "C++ clang -O3"},
          {"id": "min_max_cpp_gcc_size", "Setup": "C++ gcc -Os"},
          {"id": "min_max_cpp_gcc_speed", "Setup": "C++ gcc -O3"},
          {"id": "min_max_rust_size", "Setup": "Rust -Os"},
          {"id": "min_max_rust_speed", "Setup": "Rust -O3"},
          {"id": "min_max_rust_idiomatic_size", "Setup": "Idiomatic Rust -Os"},
          {"id": "min_max_rust_idiomatic_speed", "Setup": "Idiomatic Rust -O3"}
        ] 
      },
  "title": "Average cycles",
  "width": 500,
  "height": 300,
  "autosize": "fit",
  "mark": "bar",
  "transform": [{
    "lookup": "id",
    "as": "Cycles",
    "from": {
      "data":  {"url": "results/average_cycles.csv"},
      "key": "id",
      "fields": ["value"]
    }
  }],
  "encoding": {
    "x": {
      "field": "Setup",
      "axis": {"labelAngle": 45},
      "scale": {"padding": 0.2}
    },
    "y": {
      "field": "Cycles",
      "type": "quantitative"
    }
  }
}
....

[vegalite]
....
{
  "data": {
        "values": [
          {"id": "min_max_cpp_clang_size", "Setup": "C++ clang -Os"},
          {"id": "min_max_cpp_clang_speed", "Setup": "C++ clang -O3"},
          {"id": "min_max_cpp_gcc_size", "Setup": "C++ gcc -Os"},
          {"id": "min_max_cpp_gcc_speed", "Setup": "C++ gcc -O3"},
          {"id": "min_max_rust_size", "Setup": "Rust -Os"},
          {"id": "min_max_rust_speed", "Setup": "Rust -O3"},
          {"id": "min_max_rust_idiomatic_size", "Setup": "Idiomatic Rust -Os"},
          {"id": "min_max_rust_idiomatic_speed", "Setup": "Idiomatic Rust -O3"}
        ] 

      },
  "title": "Estimated area",
  "width": 500,
  "height": 300,
  "autosize": "fit",
  "mark": "bar",
  "transform": [{
    "lookup": "id",
    "as": "Estimated area",
    "from": {
      "data":  {"url": "results/total_estimated_area.csv"},
      "key": "id",
      "fields": ["value"]
    }
  }],
  "encoding": {
    "x": {
      "field": "Setup",
      "axis": {"labelAngle": 45},
      "scale": {"padding": 0.2}
    },
    "y": {
      "field": "Estimated area",
      "type": "quantitative"
    }
  }
}
....
// plot "results/total_cycles.csv" using 2:3:xtic(2) with boxes

