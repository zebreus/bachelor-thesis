
= Running Rust on a FPGA
:last-update-label!:
:imagesdir: images
:source-highlighter: rouge
:rouge-style: github
// We define C++ here, because the ++ is also used as a delimiter in asciidoc
:cpp: C++
:docinfo: shared,private-footer
:stem:
// :source-highlighter: highlight.js
// :highlightjs-languages: rust, cpp, console

Digital circuits are typically designed using hardware description languages (HDLs) like Verilog or VHDL. High-level synthesis (HLS) is a process that enables the design of digital circuits in a high-level language, such as C or {cpp}. HLS allows designers to write their design at a higher level of abstraction which can be more natural and familiar to software developers.

The generated circuits can be deployed to FPGAs. That can offer higher performance and lower power consumption, which can be particularly useful for applications such as high performance computing, image processing, and telecommunications.

The source languages used for HLS are usually limited subsets of C/{cpp} with some additional restrictions. Rust could be a better source for HLS, because it already has some restrictions for dealing with memory that could proof beneficial for HLS. For example its semantics define memory and ownership more clearly than C/{cpp}.

There are some ways how toolchains for HLS from Rust can be built with currently existing tooling. However, it is currently not known how viable these different toolchains would be for practical application specifically what restrictions would apply, if and how they could benefit from the additional information provided by Rust.

== Introducing the toolchain

The PandA projects maintains and develops a usable framework for research in the Hardware/Software Co-Design area. As a part of that project they also publish a HLS tool called bambu. While bambu is mostly used for research, it is also one of the most complete free and open-source HLS tools available.

It can use the clang or gcc compilers as a frontend and synthesize their output to verilog. As clang is based on LLVM, it can also load LLVM IR directly. The Rust compiler is also based on LLVM and has an option to output LLVM IR. We can then use the generated LLVM IR as an input for bambu. This way it is possible to perform High-level synthesis on Rust code.

So our toolchain uses rustc to compile rust code to LLVM IR, then uses the bambu to generate Verilog. We could then use an RTL synthesis tool like yosys to generate gate-level logic that can be deployed to a FPGA. We will not cover the last step of the toolchain here, because it is not really relevant to the topic of this blog post.

[pikchr]
....
   arrow right 150% "Rust" "Source"
   box rad 10px "Rust Compiler" "Compiler" "(rustc)" fit
   arrow right 190% "LLVM IR" "Intermediate"
   box rad 10px "PandA Bambu" "HLS Synthesizer" "(bambu)" fit
   arrow right 130% "Verilog" "RTL"
   box rad 10px "YOSYS" "RTL Synthesizer" "(yosys)" fit
   arrow right 200% "Json" "Gate-level logic"
....


== Using bambu for {cpp}

Bambu is build to synthesize C/{cpp} code.

The example for a function that finds that minimum or maximum in an array is a good example of how to write code that synthesizes well. It is just very C-like code, that mutates its inputs and has a interface that is not very Rust-like.

[source,cpp]
----
include::src/min_max_cpp.cpp[]
----

The function takes a pointer to an array of integers, the number of elements in the array, and two pointers to integers. The function will find the minimum and maximum in the array and write them to the memory locations pointed to by `out_max` and `out_min`.

We synthesize the function using bambu and use bambus integrated test runner to test the function against some testcases. Later we will use the same testcases for the Rust version of the function. The optimization level is set to `-O2` for now, which is the lowest we can go, because the Rust version requires at least some optimizations to be enabled.

We will test the performance by running the function against 21 testcases with 0 to 20 elements.

[source,console]
----
include::results/min_max_cpp_clang_intro.log[]
----

The most important aspects of the output are the average number of clock cycles and the total area used. The area is an important metric, because it is the most expensive resource on FPGAs. The number of clock cycles is also important, because it is a reasonable indicator of how fast the function is. 

The tests are executed using verilator, so they are not completly representative of the actual hardware, because Verilator does not simulate timings beyond the clock cycles. So it could be that a design requires fewer cycles, but can only be run at a lower clock frequency. That said, comparing clock cycles should be a somewhat accurate.

=== Looking at the output

The interface of the generated verilog will look something like this:

.Interface generated from {cpp} function
[symbolator]
....
include::min_max_cpp.v[]
....

The inputs are shown on the left side and the output on the right side of the module.

We can see that the module has has 3 inputs named clock, reset and start. These do pretty much what you would expect them to do. The reset is a signal that resets the module and the start signal is used to start the function. The function will not start until the start signal is high and the reset signal is low. The function will then run until it is done and the start signal goes low again. The clock signal is used to clock the module, when we talk about cycles later we are talking about clock cycles.

The module has a output named done. I assume that that goes high when the function has finished.

Then there are some in- and outputs prefixed with `M`. They are used by the module to access memory.

At last we have the four inputs of out function as 32bit wide signals. I assume that the input for `numbers_length` passes in the number as a 32 bit integer at the start. The other inputs are pointers to the memory locations where the module can find the array and the two output values.

All of this are just assumptions for now, because we did not look at the generated verilog yet.

== Using bambu for Rust

When using Rust with bambu, we need to take a few things into account.

First bambu cannot synthesize anything that unwinds the stack, at least when using the LLVM IR backend. Bambu also cannot synthesize terminating the process. This is a bit unfortunate, because unwinding and terminating are the two way that Rust uses to deal with panics. So we must make sure that our code can not panic. When optimizations are disabled, the Rust compiler sometimes inserts exception handlers into the LLVM IR, even though they are not used. On higher optimization levels, the compiler is smart enough to remove those exception handlers. 

Second, our function can not use IO and basically every other impure feature. This includes things like `std::io::println`. This does not affect us in this example, but keep it in mind when writing your own code.

Third, we need to make sure that the function interface is preserved. We can specify that we want the name to be preserved by attaching the `#[no_mangle]` attribute macro to our function. We also need a C-compatible interface, so we need to mark the function as `extern "C"`. While this is not strictly necessary, it is needed for this case, because we use bambus testbench generator to generate testcases for our function. The testbench generator only supports a C interface to call our function.

// TODO: Find example
// Luckily, Rust and LLVM are quite good at understanding out code, and they can often prove that our code can not panic. 

Fourth bambu does not support all LLVM intrinsics. Most notably bambu does not support the llvm vector reduce intrinsics, which Rust uses for vectorizing loops. There are probably other intrinsics that are not supported, but I have not encountered more yet. If we encounter an unsupported intrinsic, our easiest option is to try another optimization level or see if the Rust compiler has an option to disable the use of that intrinsic. If that does not work we can try to modify the generated LLVM IR to remove the intrinsic. A more advanced option is to write a pass for the LLVM IR that replaces the intrinsic with something that is supported by bambu. We won't do that in this blog post, but it is something to keep in mind.

=== Converting the min_max example to Rust

Translating `min_max_cpp` to Rust is not very difficult. We need to access the input array in rust using `array.get_unchecked(i)` instead of `array[i]`, because the latter is always bounds checked. If we used the checked version, our code could panic, which is not synthesizable. Finally, we need to mark the function as `#[no_mangle]`, so that the function name is preserved.

[source,rust]
----
include::src/min_max_rust.rs[]
----

If we compile that code to LLVM IR and try to use bambu with it we get an error that `llvm.vector.reduce.smax.v4i32` is not supported. As mentioned above bambu does not support llvm vector instructions. They probably get inserted by the https://llvm.org/docs/Vectorizers.html#the-loop-vectorizer[LLVM Loop Vectorizer]. We can disable that vectorization pass by passing `-C no-vectorize-loops` to rustc.

By default the Rust compiler generates code that unwinds the stack on panic. The generated LLVM IR will also have a exception handling personality function added to every function in LLVM IR. This is not synthesizable. We tell the compiler to instead terminate the program on panic by passing `-C panic=abort` to rustc.

For that reason we should also make sure that debug assertions are disabled. Debug assertions add extra safety checks, which can make it easier to find and fix bugs, but these checks usually manifest as panics. We can disable them by passing the `-C debug-assertions=off` flag. On every optimization level other than `0` they are automatically disabled, but we want to be sure.

We also need to disable overflow checks, because they will generate panics if overflows occur during arithmetic operations. We can do that by passing `-C overflow-checks=off` to rustc.

It is probably good idea to tell the rust compiler that we are not targeting a specific cpu architecture by passing `-C target-cpu=generic`.

The final command to compile the Rust code to LLVM IR is:

[source,bash]
----
rustc --emit=llvm-ir --crate-type=lib src/min_max_rust.rs -o min_max_rust.ll -C opt-level=0 -C overflow-checks=off -C no-vectorize-loops -C target-cpu=generic -C panic=abort
----

Bambu fails to synthesize the Rust code if all optimizations are disabled. Enabling at least some level of optimization in rustc or enableing a level higher than 1 in bambu fixes the problem. I assume this is because Rust still generates exception handlers in LLVM if optimizations are disabled. We will set the optimization level to `-O2` in bambu, because that way we can compare the results with the {cpp} function which also used that level.

.Synthesizing and testing the rust function
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_intro.log[]
----
====

It is quite interesting to see that the rust version of the function is apparently identical to the {cpp} version. My best guess is that rustc and clang both generated nearly identical LLVM IR, because the function is basically the same.

I would have assumed that the rust version would be slower, because the {cpp} version had optimizations enabled during compilation and synthesis, while we only had synthesis optimizations enabled for the rust version. Also bambu was designed to synthesize {cpp} code, so I assumed it might be better at synthesizing {cpp} code than rust code. I think we get this result, because bambu treats also treats both versions just as LLVM IR, so it does not have any special knowledge about {cpp}. We will do a more detailed comparison of the {cpp} and rust versions later, where the GCC backend is also included, maybe that yields better results.

== Using idiomatic Rust

While the previous example technically was Rust, it was not very Rust-like.

A more idiomatic Rust version of the same function using slices and iterators.

[source,rust]
----
include::src/min_max_rust_idiomatic.rs[]
----

The new version makes use of Rust's standard library and functional constructs such as iterators and the `fold` method. Functional programming is widely used in Rust and considered idiomatic because it is expressive and encourages best practices like immutability and explicitness. It is also safer than manually indexing into the input pointer with the `offset` method as in the previous version. Additionally, the use of a struct to return the minimum and maximum values is a more natural way to represent the output in Rust, as opposed to using two separate output pointers.

Usually idiomatic Rust-like Rust code is also faster than C-like Rust code, because the compiler can do more optimizations. So lets see if that is the case here. Bambu cannot synthesize this function when the LLVM IR was not optimized by Rust, so we will set the optimization level to `1` in Rust. This makes this result less comparable to the previous one, but it shouldn't make a big difference, because Rust does only basic optimizations at that level.

.Synthesizing and testing the idiomatic rust function
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_idiomatic_intro.log[]
----
====

The results look promising so far. This version is faster and way smaller than the previous two, but that could be because it had the rust compiler set to a higher optimization level. Lets see what happens when we synthesize our functions with all optimizations enabled.

== Evaluating the different designs

For the comparison we will use the same testcases as before. We will test every version of the function once with optimizations set for maximum speed and once with optimizations set for minimum size. For the {cpp} version we will also compare how the results change when we use gcc instead of clang.

We will consider the synthesis a blackbox, so we wont compare the generated code. We will only compare the execution time and resource usage of the generated code.

.{cpp} with clang and `-O5`
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_clang_speed.log[]
----
====

.{cpp} with clang and `-Os`
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_clang_size.log[]
----
====

.{cpp} with gcc and `-O5`
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_gcc_speed.log[]
----
====

.{cpp} with gcc and `-Os`
[%collapsible]
====
[source,console]
----
include::results/min_max_cpp_gcc_size.log[]
----
====

.Rust with `-O5` and `-C opt-level=3`
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_speed.log[]
----

When using rust optimization levels _3_ or _2_ the bambu opt level does not matter for this example.
====

.Rust with `-Os` and `-C opt-level=s`
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_size.log[]
----

When using rust optimization levels _s_ the bambu opt level does not matter for this example.
====



.Idiomatic rust with `-Os` and `-C opt-level=s`
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_idiomatic_size.log[]
----
====


.Idiomatic rust with `-O5` and `-C opt-level=3`
[%collapsible]
====
[source,console]
----
include::results/min_max_rust_idiomatic_speed.log[]
----
====

=== Comparison of the required resources

While the idiomatic version is not faster than the non-idiomatic version, it takes up the smallest area of all synthesized design. It is also more readable and easier to understand.

The area of our design is a important metric for us, because bigger circuits mean that we need a bigger more expensive FPGA. Also we can fit more things on the FPGA, if we have more area left. So area is basically the cost of our design.

While the exact amount of resources the circuit takes up depends on how we synthesize the design for hardware, bambu gives us a good estimate of how much area the design will take up. The following chart shows the area of the designs we synthesized:

:vega-lite-filename: chart_estimated_area.vl.json
include::vega-chart.adoc[]

The designs seem to divide into two groups, one with the _big designs_ (~250 logic elements) and one with the _small designs_ (~1000 logic elements). The big designs are the clang and rust designs optimized for speed. The small designs are all circuits optimized for size, but also the gcc design optimized for speed. 

It is interesting to see that gcc always generates small designs. This could be because both both rust and clang use LLVM as a backend, so they are probably optimized in a similar way. Gcc does not use LLVM, but does its own optimization passes, so it is probably optimized in a different way. It will be interesting to see if the gcc design optimized for speed still has speed comparable to the other designs optimized for speed, despite its signigicantly smaller footprint.

The versions optimized for size are smaller than the versions optimized for speed. As expected the idiomatic rust design performs better than the C-style rust design on both optimization levels. This is probably because the compiler can do more optimizations on the idiomatic version.
 
The smallest design of the bunch is the idiomatic rust design optimized for size.

=== Performance comparison

We tested each design with testcases ranging from 0 to 20 elements. The following chart shows the average number of cycles each circuit.

:vega-lite-filename: chart_average_cycles.vl.json
include::vega-chart.adoc[]

We can see that the designs optimize for speed are a bit faster than the designs optimized for size. An exception to this is again the gcc design optimized for speed, which requires a number of cycles that is more comparable to the LLVM based designs optimized for size. It is still a bit faster than the gcc design optimized for speed. It seems like the gcc backend for bambu prefers to optimize for size over speed.

The gcc designs both take the most cycles. It is interesting to see that even the gcc design optimized for speed requires more cycles than the LLVM designs optimized for size instead of speed. But the gcc design optimized for speed is still even smaller than the clang and C-style rust designs optimized for size, so it is not that surprising that it is slower.

Again the idiomatic rust design performs a the same or bit better than the C-style rust design on both optimization levels.

We can see that the designs divide in two groups again. The _low cycle designs_ that require between 15 and 17 cycles and the _high cycle designs_ that require between 22 and 26 cycles. These two groups correspond exactly to the two groups we saw in the area chart. The low cycle designs are also the big designs and the high cycle designs are the small designs.

If we look at a more detailed chart for every design we can see that they actually seem to divide into two performance groups:

:vega-lite-filename: chart_detailed_cycles.vl.json
include::vega-chart.adoc[]

While they all behave quite similar for less than four inputs, they start to diverge after that. The big designs seem to require around stem:[2*"input_length"] cycles, the small designs only take around stem:[1*"input_length"] cycles. 

The small designs all require two more cycles for every additional input element. The big designs actually also require two cycles more every additional input element but every fourth input element they actually require two cycles less. I speculate that the small designs only have one operation that processes one input element. The big designs could in addition to that also have an operation that can process four elements at once, which they use for the bulk of the computation. If the input length is not a multiple of four, they would have to do the last few elements one by one. It could be that this is the result of the LLVM compiler unrolling the loop when set to optimize for speed instead of size.

The big designs containing one operation that processes *1* element and one operation that processes *4* would also explain why these designs are roughly five times, because they include the main logic that happens inside the loop *1*+*4* times. The small designs only include the main logic that happens inside the loop *1* times. They are probably not exactly five times bigger, because there is probably some control logic that stays the same or only doubles for the designs with two operations. I assume that there are probably some optimizations that can be applied if the same operation is done multiple times simultaneously that lead to space savings.

[NOTE]
====
Here it seems like the loop is converted into two operations, one that implements a single iteration and one that implements four iterations. It would be interesting to have the ability to specify in the rust code how big these chunks could be. Maybe bambu even has this feature for {cpp} already, I have not looked into it yet.
====

Besides the amount of cycles the designs take the other relevant metric for speed is the frequency that the cycles can be executed. While the real maximum frequency is highly dependend on the hardware and the actual place and route, bambu generates a estimate of the maximum frequency of each design. I dont know how accurate they are, but they seem to be a good indicator of the performance of the designs.

:vega-lite-filename: chart_max_frequency.vl.json
include::vega-chart.adoc[]

Interestingly the gcc designs top this chart. While they performed quite poorly on the other metrics, they are capable of running at a slightly faster speed than the LLVM designs. The LLVM designs optimized for size are the second fastest designs, while the ones optimized for speed are the slowest.

There seems to be a connection between the size and the frequency of the designs. The smaller the design, the faster it can run. This compensates a bit for the fact that the smaller designs on average require more cycles to run. To get the estimated maximum performance for each design we multiply the maximum frequency with the average number of cycles required to run the design for our testcases:

:vega-lite-filename: chart_performance.vl.json
include::vega-chart.adoc[]

As expected this show that the performance gap between the big designs and the small designs is not as big as we initially expected when looking only at the required cycles

We can clearly see that the big desings are still a bit faster but not as much as we expected. The big clang design is even slower than some small designs.


:vega-lite-filename: chart_area_speed.vl.json
include::vega-chart.adoc[]

If we plot this against the area we can see that the difference in performance (stem:[+-20%]) is quite small compared to the difference in area (stem:[+-500%]). 

Also it is interesting to see that there are only two useful designs. If we want maximum speed, we should choose the idiomatic rust design optimized for speed, if we want the smallest size the choice would be the idiomatic rust design optimized for size. The other designs are not viable options, because one of these two designs will always be better on either metric.

To get the most out of our FPGA we would want to maximise the performance per area. We can calculate this by dividing the executions per second by the are:

:vega-lite-filename: chart_performance_per_area.vl.json
include::vega-chart.adoc[]

[NOTE]
====
You can click the bars in the chart to set the baseline to compare against.
====

If we compare them for space efficiency we can see that the idiomatic rust version is the most space efficient design. Surprisingly enough the gcc designs are also quite good here.

The big designs are not very space efficient, which was to be expected as they sacrificed space for speed. This tradeoff is not worth it for this design, because the problem of finding the minimum/maximum element can be parallelized quite well. We could just use two of the small designs simultaneously and get the same performance as a big design for a smaller area. We would need to implement some wrapper logic for that.

== Conclusion

It seems like High-level synthesis from Rust is possible. It performs similar, sometimes even better compared to the usual input languages like C/{cpp}. 

We only looked at a very simple design, this is probably not representative for more complex designs.

Also the process could benefit from some kinds of annotations in the Rust code to help the HLS tool better synthesize the code. I don't know if that is supported with bambu, but will look into it. Also all the parameter names get lost in the process, it would be nice if we could keep them.

Also we have no idea how the designs actually work as we just viewed the generated Verilog code as a black box. It would probably be interesting to look at the generated RTL and try to understand how the designs work.

We should also try to use a different HLS tool, like Vivado HLS, which is probably way more mature and capable than bambu. The main restriction is probably that it needs to be able to take LLVM IR as input. I am not sure if there is another free and opensource HLS tool that can process LLVM IR. It may also be feasible to generate C code from the LLVM IR and then try use a C HLS tool.